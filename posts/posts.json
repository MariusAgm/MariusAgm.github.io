[
  {
    "path": "posts/2020-12-30-el-valor-de-la-inferencia-estadstica/",
    "title": "El valor de la inferencia estadística",
    "description": "La Ley de los Rendimientos Decrecientes",
    "author": [
      {
        "name": "Mario A. García Meza",
        "url": "https://marionomics.com/about"
      }
    ],
    "date": "2020-12-30",
    "categories": [
      "Estadistica",
      "Muestreo"
    ],
    "contents": "\n\nEl Azar no es más que la medida de nuesta ignorancia.Los fenómenos fortuitos son, por definición, aquellos cuyas leyes o causas simplemente ignoramos. Henry Poincairé\n\nLa mayoría de los diseños de encuestas basan la metodología de muestreo en un tradeoff entre costos y el valor de la información que se obtiene.\nEn la mayoría de los casos en los que vale la pena hacer un estudio, los costos no permiten que este se realice usando a la población en su totalidad. Aquí es donde entra en juego el muestreo.\nLos economistas tenemos entre nuestras herramientas una que es muy útil para determinar el tamaño óptimo de una encuesta en base a los costos: la Ley de los Rendimientos decrecientes.\nPara que esta ley tenga sentido, es importante saber pensar en el margen. Pensar en el margen significa que, en lugar de pensar en el costo total de la encuesta, pensamos en el costo de una observación adicional. Cada observación adicional representa un costo adicional, derivado del tiempo que esta toma y de los recursos que se usen.\nPero también, cada observación adicional tiene un beneficio adicional en la claridad de la información. Sin embargo, si el muestreo está bien diseñado, el beneficio adicional que generan las primeras observaciones es significativamente mayor que las posteriores.\nEste beneficio es cuantificable. Se puede calcular, siempre que se tenga información suficiente sobre las desviaciones estándar de los estratos o de la población a estudiarse. Esto significa que el problema se transforma en un cálculo de optimización.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-02T18:55:37-06:00",
    "input_file": "el-valor-de-la-inferencia-estadstica.utf8.md"
  },
  {
    "path": "posts/2020-12-28-muestreo-estratificado-ciudad-de-durango/",
    "title": "Muestreo estratificado: Ciudad de Durango",
    "description": "Otro tutorial en R para hacer muestreo estratificado.",
    "author": [
      {
        "name": "Mario",
        "url": "https://marionomics.com/about"
      }
    ],
    "date": "2020-12-28",
    "categories": [
      "R",
      "Estadistica",
      "Tutoriales"
    ],
    "contents": "\nEste post es parte de una serie sobre muestreo estratificado en este blog. En esta parte de la serie vamos a hacer un ejemplo de un muestreo estratificado con datos reales del INEGI, llevando un paso más allá el ejemplo que hicimos en posts anteriores.\nDigamos que queremos hacer un estudio en la ciudad de Durango, Durango y queremos conocer cuál es el tamaño de muestra que requerimos para el mismo.\nComo vimos en este post, si nosotros tomáramos el valiente supuesto de que la población es homogénea, entonces sólo requeriríamos de la información de 384 encuestas para saber lo que necesitamos saber considerando un margen de confianza de 95% y un margen de error de 5%.\nPero como lo sabemos, a pesar de vivir en la misma zona, las personas en Durango somos muy diferentes entre si. Existen muchos factores que nos pueden generar esas diferencias, pero es el mismo investigador el que decide cuáles de estas diferencias son importantes.\nPara este ejemplo tomaremos como principal factor de diferenciación las características de la ocupación del individuo. Para eso, tomaremos la información de la encuesta intercensal 2015 para los municipios de Durango. Entramos al link previo y descargamos el archivo Excel de características económicas.\nDe la tabla que nos genera, necesitamos de dos estimadores: el valor y el error estándar. Los errores estándar nos ayudarán a generar el vector de ruido de nuestra información que nos ayudan a identificar el valor de la muestra que requerimos.\nEn la tabla siguiente, mostramos la estratificación que decidí hacer para este ejemplo, donde tomamos como un estrato a la población No Económicamente Activa (PNEA) y la Población Económicamente Activa (PEA) la segmentamos en la población No Ocupada y Ocupada. Sin embargo, la población Ocupada se divide a su vez entre los sectores en los que trabaja y el sexo de los individuos. De esta manera, vemos que la población se divide de la siguiente manera.\nEstrato\nValor\nError Estándar\nNo especificado\n252.21\n100.89\nPNEA\n235,586.00\n2,471.70\nNo ocupada\n10,933.00\n590.90\nSector Primario: Hombres\n6,977.00\n893.96\nSector Primario: Mujeres\n418.00\n251.69\nSector Secundario: Hombres\n53,439.00\n2,229.03\nSector Secundario: Mujeres\n13,769.00\n1,651.50\nSector Comercio: Hombres\n25,644.00\n1,499.21\nSector Comercio: Mujeres\n21,477.00\n2,039.55\nSector Servicios: Hombres\n68,935.00\n2,329.13\nSector Servicios: Mujeres\n64,838.00\n2,488.86\nNE: Hombres\n1,002.00\n301.19\nNE: Mujeres\n1,158.00\n467.57\n** Total**\n\n504,428.21\nPEA\n268,590.00\n\nOcupada\n257,657.00\n\nUsaremos entonces la función stratasize(), que usamos previamente en el post de muestreo estratificado.\n\n\nNh <- c(252,235586,10933,6977,418,53439,13769,25644,21477,\n        68935,64838,1002,1158)\n#Sh <- c(100,2471,591,894,252,2229,1651,1499,2039,2329,\n#        2489,301,468)\nSh <- c(0.4, 0.01, 0.05, 0.12, 0.6, 0.04, 0.11,\n        0.05, 0.09, 0.03, 0.03, 0.3, 0.4)\nsamplingbook::stratasize(0.1, Nh = Nh, Sh = Sh*100,\n                         level = 0.95, type = 'prop')\n\n\n\nstratamean object: Stratified sample size determination\n\ntype of sample: prop\n\ntotal sample size determinated: 9190\n\nEl tamaño que obtenemos es de 9 mil observaciones. Estas se tienen que dividir de manera proporcional entre los estratos.\n\n\nNh_prop <- Nh/sum(Nh)\nNh_prop <- 9190 * Nh_prop\nNh_prop\n\n\n [1]    4.591101 4292.060195  199.184562  127.111560    7.615398\n [6]  973.586736  250.852669  467.199204  391.282066 1255.903023\n[11] 1181.261191   18.255093   21.097203\n\nEsto nos indica que hay algunas secciones de la población que requieren de 4 mil observaciones y otras sólo 4.\n\n\n\n",
    "preview": {},
    "last_modified": "2020-12-28T21:58:20-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-23-cmo-calcular-el-tamao-de-muestra-en-r/",
    "title": "Como calcular el tamaño de muestra en R",
    "description": "Descripción y código",
    "author": [
      {
        "name": "Mario Alberto García-Meza",
        "url": "https://marionomics.com/about"
      }
    ],
    "date": "2020-12-23",
    "categories": [
      "R",
      "Tutorial",
      "Estadística"
    ],
    "contents": "\nLa base de la estadística inferencial es, como su nombre lo indica, obtener inferencias de una población a partir de una muestra. Normalmente es una cuestión de administración de recursos escasos lo que nos obliga a hacerlo de esta manera, por lo que una pregunta razonable en un experimento o en un estudio es ¿De qué tamaño es la muestra que se necesita?.\nUna muestra más grande genera resultados más precisos, pero esto naturalmente incrementa los costos de operación, que vienen por el tiempo, el trabajo y el dinero que se debe invertir a la recolección de la información. Por el otro lado, si un tamaño de muestra es demasiado pequeña, los resultados pierden confiabilidad.\nPara calcular el tamaño de muestra, es necesario conocer cuatro cosas\nEl tamaño de la respuesta que quieres detectar\nLa varianza de la respuesta\nLos niveles de significancia deseados\nel poder deseado\nAl tamaño de la respuesta se le puede llamar delta y se refiere a la diferencia entre los grupos de tratamiento y de control en un experimento. Definamos \\(\\Delta = \\mu_1-\\mu_2\\), donde \\(\\mu_1\\) representa a el grupo de tratamiento y \\(\\mu_2\\) es el grupo de control. Entonces entre más pequeña la diferencia que se está buscando detectar, más grande tiene que ser el tamaño de la muestra para poderlo encontrar.\nEl segundo punto es la varianza. Es el ruido que tiene nuestra información. Entre más grande sea el ruido, más grande tiene que ser el tamaño de la muestra para poder identificar las diferencias que se capturan en \\(\\Delta\\).\nDefinamos la varianza como \\(\\sigma^2\\), que nos ayuda a identificar el mencionado ruido. Entonces el tamaño del efecto combina la diferencia con la varianza y lo podemos definir con \\(\\Delta/\\sigma^2\\).\nDefinamos como \\(\\alpha\\) la probabilidad de tener un error de tipo 1, es decir, que rechacemos nuestra hipótesis nula de manera falsa, o tengamos un falso positivo. El valor de \\(\\alpha\\) se fija regularmente en 0.05, para alcanzar una significancia de 95%.\nFinalmente, tenemos que definir el poder de nuestra prueba, que definimos con \\(1-\\beta\\) donde \\(\\beta\\) representa la probabilidad de no rechazar la hipótesis nula cuando la hipótesis alternativa es verdadera (error tipo 2). Si, por ejemplo, tienes un 20% de no detectar una diferencia que es real, entonces el poder de tu prueba es de 0.8.\nCálculo del tamaño de la muestra\nEl cálculo del tamaño total de la muestra es\n\\[\\begin{equation}\n  n = \\frac{4(Z_\\alpha + Z_\\beta)^2\\sigma^2}{\\Delta^2}\n\\end{equation}\\]\nsólo cambiando \\(Z_{\\alpha}\\) por \\(Z_{\\alpha/2}\\) si la prueba es de dos lados.\nPor ejemplo, imaginemos que el tamaño de la diferencia que queremos estimar es de 20 unidades, con un poder de 90% en una prueba de dos lados con un nivel de significancia de 0.05. Investigaciones previas nos indican que la desviación estándar \\(\\sigma\\) es de alrededor de 60 unidades. Entonces\n\\[\\begin{equation}\n  n = \\frac{4(1.96 + 1.28)^2\\sigma^2}{20^2} \\approx 378\n\\end{equation}\\]\no aproximadamente 189 para cada uno de los dos grupos de tratamiento.\nCálculo en R\nLa función pwr.t.test() de la librería pwr en R está diseñada para realizar el cálculo del tamaño de muestra que nosotros buscamos.\nEsta función nos sirve para calcular el valor de nuestro estadístico \\(t\\) en función del tamaño de la muestra, pero si, en lugar de eso dejamos el parámetro \\(n\\) sin aplicar en la función, esta nos va a regresar nuestro tamaño de muestra. Veamos cómo se vería el ejemplo que hicimos anteriormente\n\n\ndelta <- 20\nsigma <- 60\nd <- delta/sigma\n\npwr::pwr.t.test(d = d,\n                sig.level = 0.5,\n                power = .90,\n                type = 'two.sample')\n\n\n\n     Two-sample t test power calculation \n\n              n = 67.18309\n              d = 0.3333333\n      sig.level = 0.5\n          power = 0.9\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-02T18:27:42-06:00",
    "input_file": "cmo-calcular-el-tamao-de-muestra-en-r.utf8.md"
  },
  {
    "path": "posts/2020-12-23-muestreo-estratificado-en-r/",
    "title": "Muestreo estratificado en R",
    "description": "Un tutorial de cómo hacer muestreo, cuando la población es más compleja.",
    "author": [
      {
        "name": "Mario A. García-Meza",
        "url": "https://marionomics.com/about"
      }
    ],
    "date": "2020-12-23",
    "categories": [],
    "contents": "\nHay que admitir que la mayoría de las ocasiones este es el caso: la población no es tan simple como para que un muestreo simple sea la solución. En este post hice un tutorial de cómo obtener los tamaños de muestra para una encuesta con una función hecha por nosotros mismos y aquí explico parte de la teoría y cómo obtener las muestras con la función pwr.t.test().\nPero en esta ocasión, vamos a llevar el análisis un paso más allá y preguntarnos que sucede si la población con la que nos encontramos tiene características heterogéneas. Y siendo sinceros, toda población que vale la pena estudiarse es al menos un poco heterogénea.\nRecordemos que nuestro objetivo es la inferencia estadística, es decir, obtener la misma información que obtendríamos de la población, pero usando un conjunto de datos más pequeño. Sin embargo, supongamos que existen tres tipos distintos de población en nuestra muestra. Estos representan el 50%, 40% y 10% de la población respectivamente. Si nosotros tomaramos una muestra uniforme, de los datos, existe la probabilidad de sobrerepresentar o subrepresentar algún estrato.\n\n\n\nNo solamente se trata de la proporción. Los estratos pueden variar en su desviación estándar. Esto hace que el muestreo estratificado proporcione una visión más clara de lo que está pasando al muestreo simple.\nVeamos cómo se realiza este muestreo. Consideremos este ejemplo, donde se encuentra la siguiente distribución de trabajadores en una compañía\nTipo de personal\nNúmero\nHombre, tiempo completo\n9000\nHombre, tiempo parcial\n1800\nMujer, tiempo completo\n900\nMujer, tiempo parcial\n6300\n–\n–\nTotal\n18000\nNaturalmente, podemos ver que los estratos difieren mucho entre si, y una distribución uniforme nos daría resultados probablemente sesgados.\nUsaremos nuevamente la librería samplingbook, pero en esta ocasión haremos uso de la función stratasize(), usando los datos de este ejemplo. Consideramos para esto que las desviaciones estándar en cada uno de los estratos están dados por el vector sh. También estamos considerando un margen de error de 10%.\n\n\nNh <- c(9000,1800,900,6300)\nsh <- c(25,10,40,80)\nsum(Nh)\n\n\n[1] 18000\n\nsamplingbook::stratasize(0.1, Nh = Nh, Sh = c(5,1,4,.80),\n                         level = 0.95, type = 'prop')\n\n\n\nstratamean object: Stratified sample size determination\n\ntype of sample: prop\n\ntotal sample size determinated: 4056\n\nEn este ejemplo, los argumentos level y type vienen por default con esos valores. Sólo los estoy incluyendo con fines ilustrativos.\nNotamos aquí entonces que de los 18 mil sujetos que tenemos, sólo es necesario obtener información acerca de alrededor de 4 mil para conocerlos, de acuerdo a la información que tenemos disponible.\n¿Cuáles son aplicaciones interesantes para lo que usarías esta información?\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-02T18:56:33-06:00",
    "input_file": "muestreo-estratificado-en-r.utf8.md"
  },
  {
    "path": "posts/2021-01-11-extaccin-de-tablas-desde-pdf-con-tabula-py-en-python/",
    "title": "Extacción de tablas desde PDF con tabula-py en python",
    "description": "Un tutorial",
    "author": [
      {
        "name": "Mario A. García-Meza",
        "url": "https://marionomics.com/about"
      }
    ],
    "date": "2020-12-23",
    "categories": [],
    "contents": "\nEs muy molesto que la información disponible se encuentre en PDF. Pero a menos de que el PDF venga de un escaneado de imágen de un documento físico, es posible extraer los datos de las tablas en PDF a un formato más manejable, como csv.\nPara lograrlo, necesitamos solamente python. Yo hice la extracción usando únicamente la terminal, pero puedes hacer el script completo y correrlo, si así lo deseas.\nUsando tábula\nEl primer paso es instalar tabula usando pip desde terminal usando\n\n\n\nEl módulo tabula-py es muy sencillo pero poderoso. Simplemente ubica el working directory en la carpeta donde se encuentra el archivo PDF que queremos extraer y ejecuta el siguiente comando:\n\n\n\nCambia archivo.pdf por el nombre del documento que te interesa (e incluye la ruta del archivo, si es necesario). En mi caso, este era un documento PDF con una tabla que ocupaba 1064 páginas (lo cual hacía poco factible la idea de etraer los datos de manera manual). Esto se expresa en el argumento pages. El agrumento encoding nos permite usar la codificación UTF-8, que es muy útil si estás trabajando con documentos en español.\nSi el documento que obtienes de aquí es de una sóla página, entonces lo único que tienes que hacer para obtener la tabla en formato csv es ejecutar el siguiente código:\n\n\n\nCambia tabla.csv por el nombre del documento que quieras obtener en formato csv. En mi caso, esto no resultó ser tan sencillo, pues el documento tenía 1064 páginas, por lo que df[0], por ejemplo, me mostraba en la consola la tabla correspondiente a la primera página del documento.\nGenerar múltiples archivos csv\nLo que hice ante esta situación fue generar en loop todos los archivos csv con un ciclo for en python.\n\n\n\nEste ciclo genera todos los archivos en csv con todos los datos que requiero. El problema es que tal vez tener múltiples archivos no sea tan práctico como tener una base de datos unificada. Para esto, podemos unir los archivos usando pd.concat() con la librería pandas. Esto funciona si la base de datos es bien comportada.\nComo este no fue mi caso (casi nunca lo es), usé un script sencillo también de python que hace un ciclo for para extraer las filas de cada uno de los archivos y los unifica en un sólo csv.\nUnificar la base de datos\nAprovechando que las bases de datos se generan en un ciclo con diferentes archivos que tienen el mismo nombre y sólamente diferenciados por el número, usamos el siguiente scipt en Python.\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-11T15:30:24-06:00",
    "input_file": "extaccin-de-tablas-desde-pdf-con-tabula-py-en-python.utf8.md"
  }
]
