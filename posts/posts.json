[
  {
    "path": "posts/2021-01-16-sumatorias-en-r/",
    "title": "Sumatorias en R",
    "description": "Bases de R.",
    "author": [
      {
        "name": "Mario A. García-Meza",
        "url": {}
      }
    ],
    "date": "2021-01-16",
    "categories": [
      "R",
      "Tutorial"
    ],
    "contents": "\n¿Te has topado ecuaciones que tienen este símbolo intimidante?: \\(\\sum\\). No temas más, en esta sección te voy a enseñar que es, cómo utilizarlo y por qué es tan popular. En poco tiempo estarás luciendo tus ecuaciones con sumatorias tú también.\nSe trata de la sumatoria. No es más que un indicador de que es necesario iterar entre los elementos de una lista y sumarlos todos. Por ejemplo,\n\\[\\begin{equation}\\label{sumatoria}\n  \\sum_{i=1}^n x_i,\n\\end{equation}\\]\nes lo mismo que decir\n\\[\\begin{equation}\nx_1+ x_2 + \\cdots + x_n.\n\\end{equation}\\]\nEsto significa que \\(i\\) va a tomar los valores desde el 1 al \\(n\\). De manera implícita, estamos diciendo que existe una lista de valores que hemos nombrado \\(x_1\\), \\(x_2\\) y así hasta el valor que toma \\(n\\). Si \\(n = 10\\), entonces esto significa que tenemos una lista con 10 elementos y la ecuación  nos dice que queremos sumar todos los elementos de esta lista.\nEl equivalente en R es la función sum(). Digamos que tenemos un vector al que llamaremos x y que definimos con\n\n\n\nPodemos llamar al elemento \\(x_1\\) usando x[1]. De hecho, si imaginamos que \\(i\\) puede tomar cualquier valor entre 1 y 10, que es el tamaño de x, entonces x[i] nos muestra el \\(i\\)-ésimo elemento de nuestra lista. Para hacer la sumatoria en R, no se necesita más que teclear\n\n[1] 143\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-16T16:09:25-06:00",
    "input_file": "sumatorias-en-r.utf8.md"
  },
  {
    "path": "posts/2021-01-15-cmo-mandar-calificaciones-al-correo-de-manera-automatizada/",
    "title": "Cómo mandar calificaciones al correo de manera automatizada",
    "description": "Una guía para profesores",
    "author": [
      {
        "name": "Mario A. García-Meza",
        "url": {}
      }
    ],
    "date": "2021-01-15",
    "categories": [
      "Enseñanza",
      "Hacks",
      "scripts",
      "Google"
    ],
    "contents": "\nNo les quería subir el archivo de Excel y exponer las calificaciones de todos ante los demás. Pero entregarlas de manera individual es demasiado trabajo y las probabilidades de error son muchas. ¿Cómo entregar las calificaciones de manera individual por correo?\nSi tu eres como yo, probablemente tienes las calificaciones de tus alumnos en un archivo de Excel que extrae las calificaciones que se generan a partir de las entregas en el sistema de gestión de clases (Moodle o Google Classroom). Si es así, este tutorial te puede servir.\nLo único que necesitas es una cuenta de developer de Google, un correo de Google (tal vez te convenga que no sea el correo personal) y tu lista de calificaciones en una hoja de cálculo de Google Sheets. Puedes subir el archivo en Excel y guardarlo en Google Drive como hoja de cálculo de Google.\nPrepara el archivo Excel\nNecesitamos que en una columna del archivo esté el nombre del alumno (preferible), el correo electrónico (indispensable) y las calificaciones en una columna aparte. Recuérdale a tus alumnos que actualicen su dirección de correo y se aseguren de que es correcta.\nEn una columna puedes generar el mensaje que quieres que incluya el correo. Te muestro un ejemplo de cómo se ve la fórmula que yo usé para hacer el mensaje:\n=CONCATENATE(\"Hola \",A2,\". Espero primeramente que te encuentres muy bien. Tu calificación final es de \", ROUND(AB2,2), \", según los archivos del SUV y el modelo de calificación que acordamos al inicio de la clase. En esta consideración tu estatus es \",AD2)\nCambia A2 y el resto de las celdas por las que contienen la información que necesitas, como el nombre, la calificación y otros detalles. Por ejemplo, en la celda AD2 yo expreso si el alumno está reprobado, aprobado, exento, u otras características que dependen de la calificación únicamente. Todas estas fueron generadas con fórmula, de tal modo que no tuve que escribirlo yo directamente, ahorrandome la probabilidad de errores en el mensaje.\nScripts en Google\nAbre un nuevo script en scripts.google.com. Si necesitas ayuda puedes ver el tutorial en la página de desarrolladores de Google.\nEscribe el siguiente código\n/**\n * Sends emails with data from the current spreadsheet.\n */\nfunction sendEmails() {\n  var sheet = SpreadsheetApp.openById(\"id_de_la_hoja_de_calculo\").getSheets()[0];\n  //var sheet = SpreadsheetApp.getActiveSheet();\n  var startRow = 2; // First row of data to process\n  var numRows = 38; // Number of rows to process\n  // Fetch the range of cells A2:B3\n  var dataRange = sheet.getRange(startRow, 1, numRows, 30);\n  // Fetch values for each row in the Range.\n  var data = dataRange.getValues();\n  for (var i in data) {\n    var row = data[i];\n    var emailAddress = row[2]; // Third column\n    var message = row[28]; // Columna 29\n    var subject = 'Calificaciones';\n    MailApp.sendEmail(emailAddress, subject, message);\n  }\n}\nCambia el ID de la hoja de cálculo de Google. Esa la puedes identificar en el navegador cuando la hoja está abierta. Abre la barra de navegación e identifícala. Es lo que viene después de /d/. Por ejemplo\n\nCambia también la fila de inicio `startRow` y el número de filas `numRows`. En mi caso requiero de 38 filas porque son el número de alumnos que tengo en ese grupo y estoy saltando la fila de los nombres de variable.\n\nSólo queda modificar el ciclo `for`, especificando la fila en la que se encuentra cada cosa. Es importante recordar que los lenguajes de programación comienzan sus iteraciones en 0, por lo que si deseas extraer la columna 3, necesitas poner `row[2]`; lo mismo aplica para el mensaje, tienes que ubicar la fila en la que se encuentra. En mi caso está en la columna 29, por lo que `row[28]` logró extraerlo. Escribe en `var subject` el título del correo.\n\nAprieta el botón **Run** y verifica en tu correo que se mandó. Recuerda que el script se debe correr con la misma cuenta de Google con la del archivo en Drive. También recuerda que Google te permite mandar hasta 100 correos diariamente y 1000 si tienes una cuenta en GSuite.\n\n```{.r .distill-force-highlighting-css}\n\n\n",
    "preview": {},
    "last_modified": "2021-01-15T14:45:43-06:00",
    "input_file": "cmo-mandar-calificaciones-al-correo-de-manera-automatizada.utf8.md"
  },
  {
    "path": "posts/2021-01-15-pensar-en-causalidad-es-pensar-como-economista/",
    "title": "Pensar en causalidad es pensar como economista",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Mario A. García-Meza",
        "url": {}
      }
    ],
    "date": "2021-01-15",
    "categories": [
      "Causalidad",
      "Economía",
      "Trabajo",
      "Migración"
    ],
    "contents": "\nEl trabajo más importante que hace un economista aplicado se llama identificación causal. Esto es lo que distingue a los verdaderos economistas del resto de los mortales: la habilidad de realizar inferencias correctas de las causas de un fenómeno (normalmente) social.\nPor ejemplo, consideremos la migración. La migración es un tema muy recurrente en las discusiones de política alrededor del mundo. Es con la retórica con la que se hizo el referéndum en Reino Unido que nos llevó al Brexit y con la que Donald Trump ganó la presidencia en las elecciones de 2016.\nExiste una lógica detrás de esa retórica. Una lógica que tristemente parece resonar con muchas personas, a pesar de lo que pueda mostrar la evidencia, y es que el flujo de migrantes de un país pobre a un país rico trae como consecuencia mayor oferta de trabajo no-calificado. Esto implicaría que más personas compiten por los mismos puestos de trabajo, lo cual traería desempleo y baja general en los salarios.\nLa realidad, naturalmente, es más compleja de lo que parece a simple vista. En 1980, hubo una migración en masa que salió del puerto de Mariel a los Estados Unidos. Diez mil cubanos llegaron al puerto de Miami sin nada más que con lo que pudieron cargar en sus manos. Un escenario de horror si la hipótesis del desempleo causado por la migración es verdad.\nSin embargo, lo que se observó fue sorprendente. En 1990, el economista David Card recopiló información de los hechos . La fuerza laboral de Miami sufrió un incremento de 7% prácticamente de la noche a la mañana. Sin embargo, ni los salarios ni el nivel de empleo parece haber sido afectado por este fenómeno.\nSi eres un lector curioso (y seguramente lo eres, si has llegado hasta este punto), seguramente te preguntarás cuál es la causa de que no se haya dado ningún efecto. Responder a esto requiere comprender la forma en la que las personas y las empresas se comportan y no dejarse confundir por señales falsas que los datos pueden arrojar. En otras palabras, requiere pensar como economista.\nSi bien es verdad que existe mayor oferta de trabajo (los economistas consideramos oferta a las personas que ofrecen sus servicios en el mercado laboral) también es verdad que la migración suele traer consigo mayor demanda. Las personas tienen necesidades que cubrir desde el primer momento en el que llegan a un lugar nuevo: comida, ropa, hogar, cortes de cabello.\nLa demanda de estas nuevas personas en la economía requiere que las empresas establecidad tengan que contratar más, haciendo que el mercado se compense. Esto fue posible en el caso de los migrantes del puerto de Mariel porque Miami ya tenía migrantes del mismo país y la comunidad Cubana le dió a los nuevos integrantes el apoyo necesario para que salieran adelante.\nExisten muchas lecciones que aprender sobre lo que deberíamos hacer para enfrentar los retos de la migración, que no son menores y que seguirán con nosotros por los años venideros.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-15T16:46:51-06:00",
    "input_file": "pensar-en-causalidad-es-pensar-como-economista.utf8.md"
  },
  {
    "path": "posts/2020-12-30-el-valor-de-la-inferencia-estadstica/",
    "title": "El valor de la inferencia estadística",
    "description": "La Ley de los Rendimientos Decrecientes",
    "author": [
      {
        "name": "Mario A. García Meza",
        "url": "https://marionomics.com/about"
      }
    ],
    "date": "2020-12-30",
    "categories": [
      "Estadistica",
      "Muestreo"
    ],
    "contents": "\n\nEl Azar no es más que la medida de nuesta ignorancia.Los fenómenos fortuitos son, por definición, aquellos cuyas leyes o causas simplemente ignoramos. Henry Poincairé\n\nLa mayoría de los diseños de encuestas basan la metodología de muestreo en un tradeoff entre costos y el valor de la información que se obtiene.\nEn la mayoría de los casos en los que vale la pena hacer un estudio, los costos no permiten que este se realice usando a la población en su totalidad. Aquí es donde entra en juego el muestreo.\nLos economistas tenemos entre nuestras herramientas una que es muy útil para determinar el tamaño óptimo de una encuesta en base a los costos: la Ley de los Rendimientos decrecientes.\nPara que esta ley tenga sentido, es importante saber pensar en el margen. Pensar en el margen significa que, en lugar de pensar en el costo total de la encuesta, pensamos en el costo de una observación adicional. Cada observación adicional representa un costo adicional, derivado del tiempo que esta toma y de los recursos que se usen.\nPero también, cada observación adicional tiene un beneficio adicional en la claridad de la información. Sin embargo, si el muestreo está bien diseñado, el beneficio adicional que generan las primeras observaciones es significativamente mayor que las posteriores.\nEste beneficio es cuantificable. Se puede calcular, siempre que se tenga información suficiente sobre las desviaciones estándar de los estratos o de la población a estudiarse. Esto significa que el problema se transforma en un cálculo de optimización.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-02T18:55:37-06:00",
    "input_file": "el-valor-de-la-inferencia-estadstica.utf8.md"
  },
  {
    "path": "posts/2020-12-28-muestreo-estratificado-ciudad-de-durango/",
    "title": "Muestreo estratificado: Ciudad de Durango",
    "description": "Otro tutorial en R para hacer muestreo estratificado.",
    "author": [
      {
        "name": "Mario",
        "url": "https://marionomics.com/about"
      }
    ],
    "date": "2020-12-28",
    "categories": [
      "R",
      "Estadistica",
      "Tutoriales"
    ],
    "contents": "\nEste post es parte de una serie sobre muestreo estratificado en este blog. En esta parte de la serie vamos a hacer un ejemplo de un muestreo estratificado con datos reales del INEGI, llevando un paso más allá el ejemplo que hicimos en posts anteriores.\nDigamos que queremos hacer un estudio en la ciudad de Durango, Durango y queremos conocer cuál es el tamaño de muestra que requerimos para el mismo.\nComo vimos en este post, si nosotros tomáramos el valiente supuesto de que la población es homogénea, entonces sólo requeriríamos de la información de 384 encuestas para saber lo que necesitamos saber considerando un margen de confianza de 95% y un margen de error de 5%.\nPero como lo sabemos, a pesar de vivir en la misma zona, las personas en Durango somos muy diferentes entre si. Existen muchos factores que nos pueden generar esas diferencias, pero es el mismo investigador el que decide cuáles de estas diferencias son importantes.\nPara este ejemplo tomaremos como principal factor de diferenciación las características de la ocupación del individuo. Para eso, tomaremos la información de la encuesta intercensal 2015 para los municipios de Durango. Entramos al link previo y descargamos el archivo Excel de características económicas.\nDe la tabla que nos genera, necesitamos de dos estimadores: el valor y el error estándar. Los errores estándar nos ayudarán a generar el vector de ruido de nuestra información que nos ayudan a identificar el valor de la muestra que requerimos.\nEn la tabla siguiente, mostramos la estratificación que decidí hacer para este ejemplo, donde tomamos como un estrato a la población No Económicamente Activa (PNEA) y la Población Económicamente Activa (PEA) la segmentamos en la población No Ocupada y Ocupada. Sin embargo, la población Ocupada se divide a su vez entre los sectores en los que trabaja y el sexo de los individuos. De esta manera, vemos que la población se divide de la siguiente manera.\nEstrato\nValor\nError Estándar\nNo especificado\n252.21\n100.89\nPNEA\n235,586.00\n2,471.70\nNo ocupada\n10,933.00\n590.90\nSector Primario: Hombres\n6,977.00\n893.96\nSector Primario: Mujeres\n418.00\n251.69\nSector Secundario: Hombres\n53,439.00\n2,229.03\nSector Secundario: Mujeres\n13,769.00\n1,651.50\nSector Comercio: Hombres\n25,644.00\n1,499.21\nSector Comercio: Mujeres\n21,477.00\n2,039.55\nSector Servicios: Hombres\n68,935.00\n2,329.13\nSector Servicios: Mujeres\n64,838.00\n2,488.86\nNE: Hombres\n1,002.00\n301.19\nNE: Mujeres\n1,158.00\n467.57\n** Total**\n\n504,428.21\nPEA\n268,590.00\n\nOcupada\n257,657.00\n\nUsaremos entonces la función stratasize(), que usamos previamente en el post de muestreo estratificado.\n\n\nNh <- c(252,235586,10933,6977,418,53439,13769,25644,21477,\n        68935,64838,1002,1158)\n#Sh <- c(100,2471,591,894,252,2229,1651,1499,2039,2329,\n#        2489,301,468)\nSh <- c(0.4, 0.01, 0.05, 0.12, 0.6, 0.04, 0.11,\n        0.05, 0.09, 0.03, 0.03, 0.3, 0.4)\nsamplingbook::stratasize(0.1, Nh = Nh, Sh = Sh*100,\n                         level = 0.95, type = 'prop')\n\n\n\nstratamean object: Stratified sample size determination\n\ntype of sample: prop\n\ntotal sample size determinated: 9190\n\nEl tamaño que obtenemos es de 9 mil observaciones. Estas se tienen que dividir de manera proporcional entre los estratos.\n\n\nNh_prop <- Nh/sum(Nh)\nNh_prop <- 9190 * Nh_prop\nNh_prop\n\n\n [1]    4.591101 4292.060195  199.184562  127.111560    7.615398\n [6]  973.586736  250.852669  467.199204  391.282066 1255.903023\n[11] 1181.261191   18.255093   21.097203\n\nEsto nos indica que hay algunas secciones de la población que requieren de 4 mil observaciones y otras sólo 4.\n\n\n\n",
    "preview": {},
    "last_modified": "2020-12-28T21:58:20-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-23-cmo-calcular-el-tamao-de-muestra-en-r/",
    "title": "Como calcular el tamaño de muestra en R",
    "description": "Descripción y código",
    "author": [
      {
        "name": "Mario Alberto García-Meza",
        "url": "https://marionomics.com/about"
      }
    ],
    "date": "2020-12-23",
    "categories": [
      "R",
      "Tutorial",
      "Estadística"
    ],
    "contents": "\nLa base de la estadística inferencial es, como su nombre lo indica, obtener inferencias de una población a partir de una muestra. Normalmente es una cuestión de administración de recursos escasos lo que nos obliga a hacerlo de esta manera, por lo que una pregunta razonable en un experimento o en un estudio es ¿De qué tamaño es la muestra que se necesita?.\nUna muestra más grande genera resultados más precisos, pero esto naturalmente incrementa los costos de operación, que vienen por el tiempo, el trabajo y el dinero que se debe invertir a la recolección de la información. Por el otro lado, si un tamaño de muestra es demasiado pequeña, los resultados pierden confiabilidad.\nPara calcular el tamaño de muestra, es necesario conocer cuatro cosas\nEl tamaño de la respuesta que quieres detectar\nLa varianza de la respuesta\nLos niveles de significancia deseados\nel poder deseado\nAl tamaño de la respuesta se le puede llamar delta y se refiere a la diferencia entre los grupos de tratamiento y de control en un experimento. Definamos \\(\\Delta = \\mu_1-\\mu_2\\), donde \\(\\mu_1\\) representa a el grupo de tratamiento y \\(\\mu_2\\) es el grupo de control. Entonces entre más pequeña la diferencia que se está buscando detectar, más grande tiene que ser el tamaño de la muestra para poderlo encontrar.\nEl segundo punto es la varianza. Es el ruido que tiene nuestra información. Entre más grande sea el ruido, más grande tiene que ser el tamaño de la muestra para poder identificar las diferencias que se capturan en \\(\\Delta\\).\nDefinamos la varianza como \\(\\sigma^2\\), que nos ayuda a identificar el mencionado ruido. Entonces el tamaño del efecto combina la diferencia con la varianza y lo podemos definir con \\(\\Delta/\\sigma^2\\).\nDefinamos como \\(\\alpha\\) la probabilidad de tener un error de tipo 1, es decir, que rechacemos nuestra hipótesis nula de manera falsa, o tengamos un falso positivo. El valor de \\(\\alpha\\) se fija regularmente en 0.05, para alcanzar una significancia de 95%.\nFinalmente, tenemos que definir el poder de nuestra prueba, que definimos con \\(1-\\beta\\) donde \\(\\beta\\) representa la probabilidad de no rechazar la hipótesis nula cuando la hipótesis alternativa es verdadera (error tipo 2). Si, por ejemplo, tienes un 20% de no detectar una diferencia que es real, entonces el poder de tu prueba es de 0.8.\nCálculo del tamaño de la muestra\nEl cálculo del tamaño total de la muestra es\n\\[\\begin{equation}\n  n = \\frac{4(Z_\\alpha + Z_\\beta)^2\\sigma^2}{\\Delta^2}\n\\end{equation}\\]\nsólo cambiando \\(Z_{\\alpha}\\) por \\(Z_{\\alpha/2}\\) si la prueba es de dos lados.\nPor ejemplo, imaginemos que el tamaño de la diferencia que queremos estimar es de 20 unidades, con un poder de 90% en una prueba de dos lados con un nivel de significancia de 0.05. Investigaciones previas nos indican que la desviación estándar \\(\\sigma\\) es de alrededor de 60 unidades. Entonces\n\\[\\begin{equation}\n  n = \\frac{4(1.96 + 1.28)^2\\sigma^2}{20^2} \\approx 378\n\\end{equation}\\]\no aproximadamente 189 para cada uno de los dos grupos de tratamiento.\nCálculo en R\nLa función pwr.t.test() de la librería pwr en R está diseñada para realizar el cálculo del tamaño de muestra que nosotros buscamos.\nEsta función nos sirve para calcular el valor de nuestro estadístico \\(t\\) en función del tamaño de la muestra, pero si, en lugar de eso dejamos el parámetro \\(n\\) sin aplicar en la función, esta nos va a regresar nuestro tamaño de muestra. Veamos cómo se vería el ejemplo que hicimos anteriormente\n\n\ndelta <- 20\nsigma <- 60\nd <- delta/sigma\n\npwr::pwr.t.test(d = d,\n                sig.level = 0.5,\n                power = .90,\n                type = 'two.sample')\n\n\n\n     Two-sample t test power calculation \n\n              n = 67.18309\n              d = 0.3333333\n      sig.level = 0.5\n          power = 0.9\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-02T18:27:42-06:00",
    "input_file": "cmo-calcular-el-tamao-de-muestra-en-r.utf8.md"
  },
  {
    "path": "posts/2020-12-23-muestreo-estratificado-en-r/",
    "title": "Muestreo estratificado en R",
    "description": "Un tutorial de cómo hacer muestreo, cuando la población es más compleja.",
    "author": [
      {
        "name": "Mario A. García-Meza",
        "url": "https://marionomics.com/about"
      }
    ],
    "date": "2020-12-23",
    "categories": [],
    "contents": "\nHay que admitir que la mayoría de las ocasiones este es el caso: la población no es tan simple como para que un muestreo simple sea la solución. En este post hice un tutorial de cómo obtener los tamaños de muestra para una encuesta con una función hecha por nosotros mismos y aquí explico parte de la teoría y cómo obtener las muestras con la función pwr.t.test().\nPero en esta ocasión, vamos a llevar el análisis un paso más allá y preguntarnos que sucede si la población con la que nos encontramos tiene características heterogéneas. Y siendo sinceros, toda población que vale la pena estudiarse es al menos un poco heterogénea.\nRecordemos que nuestro objetivo es la inferencia estadística, es decir, obtener la misma información que obtendríamos de la población, pero usando un conjunto de datos más pequeño. Sin embargo, supongamos que existen tres tipos distintos de población en nuestra muestra. Estos representan el 50%, 40% y 10% de la población respectivamente. Si nosotros tomaramos una muestra uniforme, de los datos, existe la probabilidad de sobrerepresentar o subrepresentar algún estrato.\n\n\n\nNo solamente se trata de la proporción. Los estratos pueden variar en su desviación estándar. Esto hace que el muestreo estratificado proporcione una visión más clara de lo que está pasando al muestreo simple.\nVeamos cómo se realiza este muestreo. Consideremos este ejemplo, donde se encuentra la siguiente distribución de trabajadores en una compañía\nTipo de personal\nNúmero\nHombre, tiempo completo\n9000\nHombre, tiempo parcial\n1800\nMujer, tiempo completo\n900\nMujer, tiempo parcial\n6300\n–\n–\nTotal\n18000\nNaturalmente, podemos ver que los estratos difieren mucho entre si, y una distribución uniforme nos daría resultados probablemente sesgados.\nUsaremos nuevamente la librería samplingbook, pero en esta ocasión haremos uso de la función stratasize(), usando los datos de este ejemplo. Consideramos para esto que las desviaciones estándar en cada uno de los estratos están dados por el vector sh. También estamos considerando un margen de error de 10%.\n\n\nNh <- c(9000,1800,900,6300)\nsh <- c(25,10,40,80)\nsum(Nh)\n\n\n[1] 18000\n\nsamplingbook::stratasize(0.1, Nh = Nh, Sh = c(5,1,4,.80),\n                         level = 0.95, type = 'prop')\n\n\n\nstratamean object: Stratified sample size determination\n\ntype of sample: prop\n\ntotal sample size determinated: 4056\n\nEn este ejemplo, los argumentos level y type vienen por default con esos valores. Sólo los estoy incluyendo con fines ilustrativos.\nNotamos aquí entonces que de los 18 mil sujetos que tenemos, sólo es necesario obtener información acerca de alrededor de 4 mil para conocerlos, de acuerdo a la información que tenemos disponible.\n¿Cuáles son aplicaciones interesantes para lo que usarías esta información?\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-02T18:56:33-06:00",
    "input_file": "muestreo-estratificado-en-r.utf8.md"
  },
  {
    "path": "posts/2021-01-11-extaccin-de-tablas-desde-pdf-con-tabula-py-en-python/",
    "title": "Extacción de tablas desde PDF con tabula-py en python",
    "description": "Un tutorial",
    "author": [
      {
        "name": "Mario A. García-Meza",
        "url": "https://marionomics.com/about"
      }
    ],
    "date": "2020-12-23",
    "categories": [
      "Python",
      "Extracción de Datos"
    ],
    "contents": "\nEs muy molesto que la información disponible se encuentre en PDF. Pero a menos de que el PDF venga de un escaneado de imágen de un documento físico, es posible extraer los datos de las tablas en PDF a un formato más manejable, como csv.\nPara lograrlo, necesitamos solamente python. Yo hice la extracción usando únicamente la terminal, pero puedes hacer el script completo y correrlo, si así lo deseas.\nUsando tábula\nEl primer paso es instalar tabula usando pip desde terminal usando\npip install tabula-py\nEl módulo tabula-py es muy sencillo pero poderoso. Simplemente ubica el working directory en la carpeta donde se encuentra el archivo PDF que queremos extraer y ejecuta el siguiente comando:\ndf = tabula.read_pdf(\"archivo.pdf\", encoding='utf-8', pages='1-1064')\nCambia archivo.pdf por el nombre del documento que te interesa (e incluye la ruta del archivo, si es necesario). En mi caso, este era un documento PDF con una tabla que ocupaba 1064 páginas (lo cual hacía poco factible la idea de etraer los datos de manera manual). Esto se expresa en el argumento pages. El agrumento encoding nos permite usar la codificación UTF-8, que es muy útil si estás trabajando con documentos en español.\nSi el documento que obtienes de aquí es de una sóla página, entonces lo único que tienes que hacer para obtener la tabla en formato csv es ejecutar el siguiente código:\ndf.to_csv('tabla.csv', encoding='utf-8')\nCambia tabla.csv por el nombre del documento que quieras obtener en formato csv. En mi caso, esto no resultó ser tan sencillo, pues el documento tenía 1064 páginas, por lo que df[0], por ejemplo, me mostraba en la consola la tabla correspondiente a la primera página del documento.\nGenerar múltiples archivos csv\nLo que hice ante esta situación fue generar en loop todos los archivos csv con un ciclo for en python.\nfor page in range(0,1064) \\t df[page].to_csv('tabla'+str(page)+'.csv', encoding='utf-8')\nEste ciclo genera todos los archivos en csv con todos los datos que requiero. El problema es que tal vez tener múltiples archivos no sea tan práctico como tener una base de datos unificada. Para esto, podemos unir los archivos usando pd.concat() con la librería pandas. Esto funciona si la base de datos es bien comportada.\nComo este no fue mi caso (casi nunca lo es), usé un script sencillo también de python que hace un ciclo for para extraer las filas de cada uno de los archivos y los unifica en un sólo csv.\nUnificar la base de datos\nAprovechando que las bases de datos se generan en un ciclo con diferentes archivos que tienen el mismo nombre y sólamente diferenciados por el número, usamos el siguiente script en Python.\nfout = open(\"tabla_consolidada.csv\", \"a\") for line in open(\"tabla0.csv\"): fout.write(line) for num in range(1,1063): \\t f = open(\"tabla\"+str(num)+\".csv\") \\t for line in f: \\t \\tfout.write(line) \\t f.close() fout.close()\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-11T15:46:28-06:00",
    "input_file": "extaccin-de-tablas-desde-pdf-con-tabula-py-en-python.utf8.md"
  }
]
